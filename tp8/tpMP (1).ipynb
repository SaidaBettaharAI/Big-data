{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBUWkgwYIjh6",
        "outputId": "79799f05-ebb9-4408-d003-23f88f0866f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Count Results\n",
            "data: 3\n",
            "spark: 2\n",
            "big: 2\n",
            "makes: 1\n",
            "easy: 1\n",
            "needs: 1\n",
            "power: 1\n",
            "python: 1\n",
            "is: 1\n",
            "great: 1\n",
            "for: 1\n",
            "processing: 1\n",
            "\n",
            " Total Revenue per Region\n",
            "North → 239.40\n",
            "South → 221.40\n",
            "East → 305.40\n",
            "West → 268.60\n",
            "\n",
            " Total Revenue per Product\n",
            "Apple → 325.20\n",
            "Banana → 144.00\n",
            "Orange → 146.80\n",
            "Grapes → 418.80\n",
            "\n",
            " Requests per Status Code \n",
            "HTTP 200: 10 requests\n",
            "HTTP 403: 2 requests\n",
            "HTTP 404: 5 requests\n",
            "HTTP 500: 3 requests\n",
            "HTTP Status: 1 requests\n",
            "\n",
            " Requests per URL\n",
            "/about.html: 2 requests\n",
            "/checkout: 3 requests\n",
            "/contact.html: 3 requests\n",
            "/images/logo.png: 2 requests\n",
            "/index.html: 5 requests\n",
            "/login: 2 requests\n",
            "/products.html: 3 requests\n",
            "URL: 1 requests\n",
            "\n",
            " Total Response Size per Status \n",
            "HTTP 200: 8182 bytes\n",
            "HTTP 403: 128 bytes\n",
            "HTTP 404: 2560 bytes\n",
            "HTTP 500: 384 bytes\n",
            "HTTP Status: 0 bytes\n",
            "\n",
            " Errors Only (Status != 200)\n",
            "HTTP 403: 2 requests\n",
            "HTTP 404: 5 requests\n",
            "HTTP 500: 3 requests\n",
            "HTTP Status: 1 requests\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "import re\n",
        "\n",
        "#  إنشاء ملفات تجريبية\n",
        "# data.txt - Word Count\n",
        "with open(\"data.txt\", \"w\") as f:\n",
        "    f.write(\"\"\"spark makes big data easy\n",
        "big data needs spark power\n",
        "python is great for data processing\"\"\")\n",
        "\n",
        "# sales.txt - Sales per Region\n",
        "with open(\"sales.txt\", \"w\") as f:\n",
        "    f.write(\"\"\"Product,Quantity,UnitPrice,Region\n",
        "Apple,3,2.5,North\n",
        "Banana,6,1.2,South\n",
        "Apple,1,2.5,East\n",
        "Orange,4,1.8,North\n",
        "Banana,2,1.2,South\n",
        "Apple,5,2.5,West\n",
        "Orange,3,1.8,East\n",
        "Apple,4,2.6,North\n",
        "Banana,8,1.1,East\n",
        "Apple,7,2.5,South\n",
        "Orange,5,1.9,West\n",
        "Banana,3,1.3,North\n",
        "Grapes,10,3.2,East\n",
        "Grapes,5,3.2,South\n",
        "Banana,9,1.2,West\n",
        "Apple,6,2.4,East\n",
        "Orange,4,1.8,South\n",
        "Grapes,8,3.3,North\n",
        "Apple,2,2.5,North\n",
        "Banana,5,1.2,East\n",
        "Grapes,12,3.1,West\n",
        "Apple,9,2.5,West\n",
        "Orange,7,1.7,South\n",
        "Grapes,6,3.2,East\n",
        "Banana,11,1.1,South\n",
        "Apple,10,2.6,North\n",
        "Orange,2,1.9,West\n",
        "Grapes,9,3.0,North\n",
        "Apple,3,2.4,East\n",
        "Banana,7,1.3,West\n",
        "Apple,8,2.5,South\n",
        "Orange,5,1.8,North\n",
        "Grapes,10,3.2,West\n",
        "Apple,4,2.5,East\n",
        "Banana,6,1.2,North\n",
        "Orange,9,1.9,East\n",
        "Apple,7,2.6,South\n",
        "Grapes,5,3.3,West\n",
        "Banana,12,1.1,South\n",
        "Apple,2,2.5,North\n",
        "Orange,8,1.8,West\n",
        "Grapes,7,3.1,East\n",
        "Apple,11,2.4,East\n",
        "Banana,5,1.2,West\n",
        "Orange,3,1.9,North\n",
        "Grapes,4,3.2,South\n",
        "Apple,9,2.6,North\n",
        "Banana,10,1.2,East\n",
        "Grapes,8,3.1,West\n",
        "Apple,5,2.5,South\n",
        "Orange,7,1.7,East\n",
        "Grapes,6,3.0,North\n",
        "Banana,8,1.2,South\n",
        "Apple,4,2.4,West\n",
        "Orange,9,1.8,North\n",
        "Grapes,5,3.3,East\n",
        "Banana,11,1.1,West\n",
        "Apple,3,2.5,South\n",
        "Orange,2,1.9,South\n",
        "Grapes,9,3.0,East\n",
        "Apple,8,2.6,North\n",
        "Banana,6,1.2,East\n",
        "Orange,4,1.8,West\n",
        "Grapes,10,3.2,South\n",
        "Apple,12,2.4,East\n",
        "Banana,9,1.1,North\n",
        "Orange,3,1.9,East\n",
        "Grapes,11,3.1,West\n",
        "Apple,7,2.5,South\n",
        "Banana,5,1.3,West\n",
        "Orange,6,1.8,North\n",
        "Grapes,8,3.2,East\"\"\")\n",
        "\n",
        "# weblogs.txt - HTTP Logs\n",
        "with open(\"weblogs.txt\", \"w\") as f:\n",
        "    f.write(\"\"\"# Date, Time, IP, Method, URL, Status, ResponseSize\n",
        "2025-10-10,12:01:32,192.168.1.2,GET,/index.html,200,1024\n",
        "2025-10-10,12:01:33,192.168.1.3,GET,/products.html,200,850\n",
        "2025-10-10,12:01:35,192.168.1.4,GET,/contact.html,404,512\n",
        "2025-10-10,12:01:38,192.168.1.5,POST,/checkout,500,128\n",
        "2025-10-10,12:01:41,192.168.1.6,GET,/index.html,200,1024\n",
        "2025-10-10,12:01:45,192.168.1.7,GET,/images/logo.png,200,256\n",
        "2025-10-10,12:01:48,192.168.1.8,GET,/about.html,404,512\n",
        "2025-10-10,12:01:53,192.168.1.9,POST,/login,403,64\n",
        "2025-10-10,12:02:01,192.168.1.10,GET,/index.html,200,1024\n",
        "2025-10-10,12:02:07,192.168.1.11,POST,/checkout,500,128\n",
        "2025-10-10,12:02:12,192.168.1.12,GET,/contact.html,404,512\n",
        "2025-10-10,12:02:15,192.168.1.13,GET,/index.html,200,1024\n",
        "2025-10-10,12:02:21,192.168.1.14,GET,/products.html,200,850\n",
        "2025-10-10,12:02:23,192.168.1.15,GET,/about.html,404,512\n",
        "2025-10-10,12:02:29,192.168.1.16,POST,/checkout,500,128\n",
        "2025-10-10,12:02:31,192.168.1.17,GET,/images/logo.png,200,256\n",
        "2025-10-10,12:02:34,192.168.1.18,GET,/contact.html,404,512\n",
        "2025-10-10,12:02:38,192.168.1.19,POST,/login,403,64\n",
        "2025-10-10,12:02:41,192.168.1.20,GET,/index.html,200,1024\n",
        "2025-10-10,12:02:47,192.168.1.21,GET,/products.html,200,850\"\"\")\n",
        "\n",
        "#  Word Count\n",
        "def mapper_wordcount(line):\n",
        "    words = re.findall(r\"\\b\\w+\\b\", line.lower())\n",
        "    return [(w, 1) for w in words]\n",
        "\n",
        "def group_pairs(pairs):\n",
        "    grouped = defaultdict(list)\n",
        "    for k, v in pairs:\n",
        "        grouped[k].append(v)\n",
        "    return grouped\n",
        "\n",
        "def reducer_sum(grouped):\n",
        "    return {k: sum(v) for k, v in grouped.items()}\n",
        "\n",
        "# Run Word Count\n",
        "pairs = []\n",
        "with open(\"data.txt\", \"r\") as f:\n",
        "    for line in f:\n",
        "        pairs.extend(mapper_wordcount(line))\n",
        "grouped = group_pairs(pairs)\n",
        "result_wordcount = reducer_sum(grouped)\n",
        "\n",
        "print(\"Word Count Results\")\n",
        "for word, count in sorted(result_wordcount.items(), key=lambda x: -x[1]):\n",
        "    print(f\"{word}: {count}\")\n",
        "\n",
        "#  Sales per Region\n",
        "import csv\n",
        "\n",
        "def mapper_sales(row):\n",
        "    qty = float(row['Quantity'])\n",
        "    price = float(row['UnitPrice'])\n",
        "    region = row['Region']\n",
        "    revenue = qty * price\n",
        "    return [(region, revenue)]\n",
        "\n",
        "pairs = []\n",
        "with open(\"sales.txt\", \"r\") as f:\n",
        "    reader = csv.DictReader(f)\n",
        "    for row in reader:\n",
        "        pairs.extend(mapper_sales(row))\n",
        "\n",
        "grouped = group_pairs(pairs)\n",
        "result_sales_region = reducer_sum(grouped)\n",
        "\n",
        "print(\"\\n Total Revenue per Region\")\n",
        "for region, total in result_sales_region.items():\n",
        "    print(f\"{region} → {total:.2f}\")\n",
        "\n",
        "#  Bonus: Total Revenue per Product\n",
        "\n",
        "def mapper_sales_product(row):\n",
        "    qty = float(row['Quantity'])\n",
        "    price = float(row['UnitPrice'])\n",
        "    product = row['Product']\n",
        "    revenue = qty * price\n",
        "    return [(product, revenue)]\n",
        "\n",
        "pairs = []\n",
        "with open(\"sales.txt\", \"r\") as f:\n",
        "    reader = csv.DictReader(f)\n",
        "    for row in reader:\n",
        "        pairs.extend(mapper_sales_product(row))\n",
        "\n",
        "grouped = group_pairs(pairs)\n",
        "result_sales_product = reducer_sum(grouped)\n",
        "\n",
        "print(\"\\n Total Revenue per Product\")\n",
        "for product, total in result_sales_product.items():\n",
        "    print(f\"{product} → {total:.2f}\")\n",
        "\n",
        "#  Log Analysis\n",
        "\n",
        "def mapper_status(line):\n",
        "    parts = line.strip().split(\",\")\n",
        "    if len(parts) < 6: return []\n",
        "    status = parts[5].strip()\n",
        "    return [(status, 1)] if status else []\n",
        "\n",
        "def mapper_url(line):\n",
        "    parts = line.strip().split(\",\")\n",
        "    if len(parts) < 5: return []\n",
        "    url = parts[4].strip()\n",
        "    return [(url, 1)] if url else []\n",
        "\n",
        "def mapper_status_size(line):\n",
        "    parts = line.strip().split(\",\")\n",
        "    if len(parts) < 7: return []\n",
        "    status = parts[5].strip()\n",
        "    try:\n",
        "        size = int(parts[6].strip())\n",
        "    except:\n",
        "        size = 0\n",
        "    return [(status, size)]\n",
        "\n",
        "# Status Count\n",
        "pairs = []\n",
        "with open(\"weblogs.txt\", \"r\") as f:\n",
        "    for line in f:\n",
        "        pairs.extend(mapper_status(line))\n",
        "grouped = group_pairs(pairs)\n",
        "status_counts = reducer_sum(grouped)\n",
        "\n",
        "# URL Count\n",
        "pairs = []\n",
        "with open(\"weblogs.txt\", \"r\") as f:\n",
        "    for line in f:\n",
        "        pairs.extend(mapper_url(line))\n",
        "grouped = group_pairs(pairs)\n",
        "url_counts = reducer_sum(grouped)\n",
        "\n",
        "# Status Response Size\n",
        "pairs = []\n",
        "with open(\"weblogs.txt\", \"r\") as f:\n",
        "    for line in f:\n",
        "        pairs.extend(mapper_status_size(line))\n",
        "grouped = group_pairs(pairs)\n",
        "status_sizes = reducer_sum(grouped)\n",
        "\n",
        "# Display Log Results\n",
        "print(\"\\n Requests per Status Code \")\n",
        "for status, count in sorted(status_counts.items()):\n",
        "    print(f\"HTTP {status}: {count} requests\")\n",
        "\n",
        "print(\"\\n Requests per URL\")\n",
        "for url, count in sorted(url_counts.items()):\n",
        "    print(f\"{url}: {count} requests\")\n",
        "\n",
        "print(\"\\n Total Response Size per Status \")\n",
        "for status, total_size in sorted(status_sizes.items()):\n",
        "    print(f\"HTTP {status}: {total_size} bytes\")\n",
        "\n",
        "print(\"\\n Errors Only (Status != 200)\")\n",
        "for status, count in sorted(status_counts.items()):\n",
        "    if status != '200':\n",
        "        print(f\"HTTP {status}: {count} requests\")\n"
      ]
    }
  ]
}